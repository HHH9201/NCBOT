# -*- coding: utf-8 -*-
"""
å’¸é±¼å•æœºï¼ˆå•æœºç‰ˆï¼‰+ ByrutGameï¼ˆè”æœºç‰ˆï¼‰
åŒåŒ¿ååˆå¹¶è½¬å‘å¡ç‰‡
"""
import re
import os
import json
import asyncio
import logging
import urllib3
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from ncatbot.plugin import BasePlugin, CompatibleEnrollment
from ncatbot.core.message import GroupMessage
from ncatbot.core import Text, At, Reply, MessageChain, Image

# å¼•å…¥å…¨å±€æœåŠ¡å’Œé…ç½®
from common import (
    napcat_service, ai_service, GLOBAL_CONFIG,
    image_to_base64, normalize_text, convert_roman_to_arabic,
    load_yaml, save_yaml, clean_filename,
    http_client, DEFAULT_HEADERS
)

# é…ç½®æ›´æ¸…çˆ½çš„æ—¥å¿—æ ¼å¼ï¼Œå»æ‰è¿›ç¨‹å’Œçº¿ç¨‹ä¿¡æ¯
logging.basicConfig(
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    level=logging.INFO
)

# -------------------- æå–é…ç½® --------------------
BYRUT_BASE = GLOBAL_CONFIG.get('byrut_base')
COOKIES = GLOBAL_CONFIG.get('cookies', {})

# å›¾ç‰‡è·¯å¾„å¤„ç†
TOOL_DIR = Path(__file__).parent / "tool"
QQ_IMG = str(TOOL_DIR / GLOBAL_CONFIG.get('images', {}).get('qq_img', "TG.png"))
BACKUP_IMG = str(TOOL_DIR / GLOBAL_CONFIG.get('images', {}).get('backup_img', "ç§å­.png"))

bot = CompatibleEnrollment

urllib3.disable_warnings()

CACHE_FILE = Path(__file__).parent / "game_name_cache.yaml"
_title_cache = load_yaml(CACHE_FILE)

async def translate_to_chinese_title(eng: str) -> str:
    """
    è¾“å…¥è‹±æ–‡å…³é”®è¯ï¼Œè¿”å› Steam å®˜æ–¹ä¸­æ–‡åï¼›å¤±è´¥åˆ™å›é€€åŸæ–‡ã€‚
    """
    if not eng:
        return eng

    global _title_cache
    if eng in _title_cache:
        return _title_cache[eng]

    system_prompt = "ä½ æ˜¯ Steam ä¸­æ–‡åç§°ç¿»è¯‘åŠ©æ‰‹ï¼Œåªè¾“å‡º steam æ¸¸æˆå®˜æ–¹ä¸­æ–‡åï¼Œå…¶ä½™ä»»ä½•æ–‡å­—éƒ½ä¸è¦è¯´ã€‚"
    prompt = f"{eng} çš„ Steam å®˜æ–¹æ¸¸æˆä¸­æ–‡åæ˜¯ä»€ä¹ˆ"
    
    try:
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ]
        # è°ƒç”¨AIæœåŠ¡è¿›è¡Œç¿»è¯‘
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ é€’æ­£ç¡®çš„å‚æ•°ï¼ŒåŸä»£ç ä¸­çš„PROXYå˜é‡å·²è¢«ç§»é™¤ï¼Œéœ€è¦ä»GLOBAL_CONFIGè·å–
        proxy = GLOBAL_CONFIG.get('proxy')
        zh = await ai_service.chat_completions(messages, temperature=0.1, max_tokens=30, proxy=proxy)
        
        if not zh:
            zh = eng
    except Exception as e:
        logging.error(f"ç¿»è¯‘å¤±è´¥: {e}")
        zh = eng

    _title_cache[eng] = zh
    save_yaml(CACHE_FILE, _title_cache)
    return zh

# ------------------------------------------------------------------
# 1. æå–è‹±æ–‡å…³é”®è¯ + ä¸­æ–‡å±•ç¤ºåï¼ˆè¿”å› tupleï¼‰
# ------------------------------------------------------------------
def extract_english_name(title: str) -> tuple[str, str]:

    segments = title.split('|')
    
    # å¯»æ‰¾æœ€ç®€æ´çš„è‹±æ–‡æ¸¸æˆå
    english_part = ""
    for segment in reversed(segments):  # ä»åå¾€å‰æ‰¾è‹±æ–‡æ®µ
        segment = segment.strip()
        # å¦‚æœè¿™æ®µä¸»è¦æ˜¯è‹±æ–‡å­—ç¬¦ï¼Œå°±è®¤ä¸ºæ˜¯è‹±æ–‡æ®µ
        if len(re.findall(r'[a-zA-Z]', segment)) > len(re.findall(r'[\u4e00-\u9fff]', segment)):
            english_part = segment
            break
    
    # å¦‚æœæ²¡æ‰¾åˆ°è‹±æ–‡æ®µï¼Œç”¨æœ€åä¸€æ®µ
    if not english_part:
        english_part = segments[-1] if segments else title
    
    # ä¸­æ–‡å±•ç¤ºåï¼šä»ç¬¬ä¸€ä¸ªä¸­æ–‡æ®µå¼€å§‹ï¼Œåˆ°è‹±æ–‡æ®µä¹‹å‰çš„æ‰€æœ‰æ®µ
    chinese_display_parts = []
    for segment in segments:
        segment = segment.strip()
        # å¦‚æœè¿™æ®µä¸»è¦æ˜¯è‹±æ–‡å­—ç¬¦ï¼Œå°±åœæ­¢æ”¶é›†
        if len(re.findall(r'[a-zA-Z]', segment)) > len(re.findall(r'[\u4e00-\u9fff]', segment)):
            break
        chinese_display_parts.append(segment)
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä¸­æ–‡æ®µï¼Œç”¨ç¬¬ä¸€æ®µ
    if not chinese_display_parts:
        chinese_display_parts = [segments[0]] if segments else [title]
    
    chinese_display = ' | '.join(chinese_display_parts)
    
    # æ¸…ç†è‹±æ–‡éƒ¨åˆ†ï¼šå»æ‰ç‰ˆæœ¬å·ã€å¹´ä»½ã€ç‰¹æ®Šç¬¦å·ç­‰
    # å»æ‰æ‹¬å·åŠå…¶å†…å®¹
    english_part = re.sub(r'\([^)]*\)', '', english_part)
    english_part = re.sub(r'\[[^\]]*\]', '', english_part)
    # å»æ‰æ–œæ åçš„é‡å¤å†…å®¹
    english_part = english_part.split('/')[0]
    # å»æ‰ç‰¹æ®Šç¬¦å·å’Œå¤šä½™ç©ºæ ¼
    english_part = re.sub(r'[^\w\s]', ' ', english_part)
    english_part = re.sub(r'\s+', ' ', english_part).strip()
    
    # åªä¿ç•™å‰3-4ä¸ªæ ¸å¿ƒå•è¯
    words = english_part.split()
    if len(words) > 4:
        english_part = ' '.join(words[:4])
    
    # ç½—é©¬â†’é˜¿æ‹‰ä¼¯æ•°å­—ï¼ˆä»…è‹±æ–‡å…³é”®è¯ï¼‰
    english_part = convert_roman_to_arabic(english_part)
    
    return english_part.strip(), chinese_display.strip()

# åˆ é™¤ get_text_size å‡½æ•°ï¼Œä¸å†ä½¿ç”¨

async def fetch_text(url, **kwargs):
    async with aiohttp.ClientSession(cookies=COOKIES, headers=HEADERS) as session:
        async with session.get(url, **kwargs) as resp:
            return await resp.text()

async def get_real_url(jump_url: str) -> str:
    async with aiohttp.ClientSession(cookies=COOKIES, headers=HEADERS) as s:
        async with s.head(jump_url, allow_redirects=False) as r:
            if 300 <= r.status < 400:
                return r.headers['Location']
        async with s.get(jump_url) as r:
            return str(r.url)

# -------------------- xydj æœç´¢ --------------------
async def search_game(game_name: str):
    url = f"https://www.xianyudanji.to/?cat=1&s={game_name}&order=views"
    html = await fetch_text(url, timeout=15)
    soup = BeautifulSoup(html, "lxml")
    games, seen = [], set()
    for a in soup.select("article.post-grid a[href][title]"):
        title = a['title'].strip()
        img_tag = a.select_one("img")
        img_src = img_tag['src'] if img_tag else ""
        if not title or title in seen or game_name not in title:
            continue
        seen.add(title)
        games.append({"title": title, "url": a['href'], "img": img_src})
    if not games:
        return None, None
    
    # ç›´æ¥è¿”å›æ–‡æœ¬æ ¼å¼çš„æ¸¸æˆåˆ—è¡¨ï¼Œä¸ç”Ÿæˆå›¾ç‰‡
    text_lines = []
    
    for idx, g in enumerate(games):
        # æå–æ¸¸æˆåå’Œç‰ˆæœ¬ä¿¡æ¯
        title_parts = g['title'].split('|')
        game_name = title_parts[0].strip()
        
        # æå–å…³é”®ä¿¡æ¯ï¼Œä¿æŒç®€æ´
        key_info = []
        for part in title_parts[1:]:
            part = part.strip()
            if any(keyword in part.lower() for keyword in ['v', 'ç‰ˆ', 'dlc', 'ä¸­æ–‡', 'æ‰‹æŸ„', 'æ›´æ–°', 'å¹´åº¦ç‰ˆ']):
                key_info.append(part)
        
        # æ„å»ºç¾è§‚çš„æ ¼å¼
        display_text = f"ğŸ”¹ {idx+1}. {game_name}"
        if key_info:
            display_text += f" | {' | '.join(key_info[:3])}"
        
        text_lines.append(display_text)
    
    text_result = "\n".join(text_lines)
    
    return text_result, games

# -------------------- xydj è¯¦æƒ… --------------------
async def extract_download_info(game_url: str):
    try:
        html = await fetch_text(game_url, timeout=15)
        soup = BeautifulSoup(html, "lxml")
        box = soup.select_one("#ripro_v2_shop_down-5")
        if not box:
            return ["æœªæ‰¾åˆ°ä¸‹è½½åŒºåŸŸ"]
        results = []
        
        # æå–è§£å‹å¯†ç  - æ”¯æŒä¸¤ç§ä¸åŒçš„HTMLæ ¼å¼
        password_found = False
        
        # æ–¹æ³•1: ä»æŒ‰é’®ç»„ä¸­æå–è§£å‹å¯†ç ï¼ˆç¬¬ä¸€ç§æ ¼å¼ï¼‰
        # æŸ¥æ‰¾æŒ‰é’®ç»„ä¸­åŒ…å«"è§£å‹å¯†ç "æ–‡æœ¬çš„æŒ‰é’®
        password_btns = box.select('div.btn-group button.go-copy[data-clipboard-text]')
        for btn in password_btns:
            btn_text = btn.get_text(strip=True)
            # æ£€æŸ¥æŒ‰é’®æ–‡æœ¬æˆ–ç›¸é‚»çš„é“¾æ¥æ–‡æœ¬æ˜¯å¦åŒ…å«"è§£å‹å¯†ç "
            adjacent_link = btn.find_previous_sibling('a') if btn else None
            link_text = adjacent_link.get_text(strip=True) if adjacent_link else ""
            
            if ('è§£å‹å¯†ç ' in btn_text or 'è§£å‹å¯†ç ' in link_text):
                        clipboard_text = btn.get('data-clipboard-text', '').strip()
                        if clipboard_text:  # ç¡®ä¿å¯†ç ä¸ä¸ºç©º
                            results.append(f"è§£å‹å¯†ç : ã€{clipboard_text}ã€‘")
                            password_found = True
                            break
        
        # æ–¹æ³•2: ä»down-infoåŒºåŸŸæå–è§£å‹å¯†ç ï¼ˆç¬¬äºŒç§æ ¼å¼ï¼‰
        if not password_found:
            down_info = box.select_one('div.down-info')
            if down_info:
                # æŸ¥æ‰¾åŒ…å«"è§£å‹å¯†ç "çš„liå…ƒç´ 
                password_lis = down_info.select('ul.infos li')
                for li in password_lis:
                    data_label = li.select_one('p.data-label')
                    if data_label and 'è§£å‹å¯†ç ' in data_label.get_text():
                        info_p = li.select_one('p.info')
                        if info_p:
                            # æå–å¯†ç æ–‡æœ¬ï¼Œå¯èƒ½åŒ…å«åœ¨spanæˆ–bæ ‡ç­¾å†…
                            password_span = info_p.select_one('span')
                            password_b = info_p.select_one('b')
                            
                            if password_span:
                                password = password_span.get_text(strip=True)
                            elif password_b:
                                password = password_b.get_text(strip=True)
                            else:
                                password = info_p.get_text(strip=True)
                            
                            # éªŒè¯å¯†ç æ ¼å¼å¹¶æ·»åŠ åˆ°ç»“æœ
                            if password and password != "è§£å‹å¯†ç =å®‰è£…å¯†ç ã€æ¿€æ´»ç ":  # æ’é™¤è¯´æ˜æ–‡å­—
                                results.append(f"è§£å‹å¯†ç : ã€{password}ã€‘")
                                password_found = True
                                break
        
        # æ–¹æ³•3: é€šç”¨å¤‡ç”¨æ–¹æ¡ˆ - æŸ¥æ‰¾ä»»ä½•å¯èƒ½åŒ…å«å¯†ç çš„å…ƒç´ 
        if not password_found:
            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«å¯†ç çš„å…ƒç´ 
            potential_password_elements = box.select('[data-clipboard-text]')
            for element in potential_password_elements:
                clipboard_text = element.get('data-clipboard-text', '').strip()
                element_text = element.get_text(strip=True)
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆå¯†ç æ ¼å¼
                if (clipboard_text and 
                        len(clipboard_text) >= 4 and 
                        not any(keyword in clipboard_text for keyword in ['ç™¾åº¦', 'ç½‘ç›˜', 'æå–', 'https', 'http']) and
                        ('å¯†ç ' in element_text or 'è§£å‹' in element_text)):
                        results.append(f"è§£å‹å¯†ç : ã€{clipboard_text}ã€‘")
                        password_found = True
                        break
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
        if not password_found:
            results.append("è§£å‹å¯†ç : æœªæ‰¾åˆ°")
        
        # æå–ç™¾åº¦ç½‘ç›˜æå–ç 
        bdpan_btn = None
        btn_groups = box.select('div.btn-group')
        if btn_groups:
            # æŸ¥æ‰¾åŒ…å«"ç™¾åº¦ç½‘ç›˜"çš„æŒ‰é’®ç»„
            for group in btn_groups:
                a_tag = group.select_one('a[href*="goto?down="]')
                if a_tag and 'ç™¾åº¦ç½‘ç›˜' in a_tag.get_text():
                    bdpan_btn = group.select_one('button.go-copy[data-clipboard-text]')
                    break
        
        if bdpan_btn and bdpan_btn.has_attr('data-clipboard-text'):
            results.append(f"ç™¾åº¦ç½‘ç›˜æå–ç : {bdpan_btn['data-clipboard-text'].strip()}")
        else:
            results.append("ç™¾åº¦ç½‘ç›˜æå–ç : æœªæ‰¾åˆ°")
            
        # æå–ä¸‹è½½é“¾æ¥
        for a in box.select("a[target='_blank'][href*='goto?down=']"):
            name = a.get_text(strip=True)
            if 'è§£å‹å¯†ç ' in name:
                continue
            jump_url = urljoin(game_url, a['href'])
            real_url = await get_real_url(jump_url)
            results.append(f"{name}: {real_url}")
        return results
    except Exception as e:
        return [f"è§£ææ¸¸æˆä¿¡æ¯æ—¶å‡ºé”™: {e}"]

# -------------------- ç½‘ç»œè¯·æ±‚é…ç½®å’Œé”™è¯¯å¤„ç† ----------


# -------------------- ByrutGame æœç´¢ï¼ˆå¼‚æ­¥+ä»£ç†+SSL å…³é—­ï¼‰ ----------
async def search_byrut(name: str) -> list:
    """è¿”å› [{href, title, category}, ...] æœ€å¤š3æ¡"""
    if not name:
        return []

    url = f"{BYRUT_BASE}/index.php?do=search"
    params = {
        "subaction": "search",
        "story": name
    }
    
    try:
        html = await http_client.get_text(url, params=params, verify_ssl=False)
        if not html:
            return []

        soup = BeautifulSoup(html, "html.parser")
        key = normalize_text(name)
        results, seen = [], set()
        
        for a in soup.select("a.search_res"):
            href = a["href"]
            if "po-seti" not in href.lower():   # â† åªç•™è”æœº
                continue
            title_tag = a.select_one(".search_res_title")
            if not title_tag:
                continue
            title = title_tag.get_text(strip=True)
            if key not in normalize_text(title):
                continue
            if href in seen:
                continue
            seen.add(href)
            category = (
                "è”æœºç‰ˆ"
                if any(k in href.lower() for k in ["po-seti", "onlayn", "multiplayer"])
                else "å•æœºç‰ˆ"
            )
            results.append({"href": href, "title": title, "category": category})
            
        return results[:3]   # æœ€å¤š3æ¡

    except Exception as e:
        logging.error(f"[Byrut] æœç´¢å¼‚å¸¸: {e}")
        return []


# -------------------- å¤‡ç”¨æ–¹æ¡ˆå‡½æ•° --------------------
def _apply_backup_solution(item: dict, error_type: str) -> None:
    """åº”ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼Œå½“ä¸»APIä¸å¯ç”¨æ—¶æä¾›åŸºæœ¬åŠŸèƒ½"""
    logging.info(f"[Byrut] {error_type}ï¼Œåº”ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
    
    # ä½¿ç”¨åŸå§‹é“¾æ¥ä½œä¸ºå¤‡ç”¨ä¸‹è½½é“¾æ¥
    backup_torrent_url = item.get('href', '')
    
    # æ£€æŸ¥å¤‡ç”¨å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    backup_image = str(TOOL_DIR / "ç§å­.png")
    if not os.path.exists(backup_image):
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ–‡å­—æ ‡è¯†
        backup_image = None
        logging.warning(f"[Byrut] å¤‡ç”¨å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {backup_image}")
    
    # æ›´æ–°é¡¹ç›®ä¿¡æ¯
    item.update({
        "update_time": f"APIè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨èµ„æº ({error_type})", 
        "torrent_url": backup_torrent_url,
        "backup_image": backup_image,
        "backup_mode": True  # æ ‡è®°ä¸ºå¤‡ç”¨æ¨¡å¼
    })

# -------------------- ByrutGame è¯¦æƒ…ï¼ˆå¼‚æ­¥+ä»£ç†+SSL å…³é—­ï¼‰ ----------
async def fetch_byrut_detail(item: dict) -> None:
    href = item["href"]
    # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ­£ç¡®çš„é“¾æ¥
    if href.startswith("https://byrutgame.org"):
        proxy_url = href
    else:
        detail_path = href.replace("https://napcat.1783069903.workers.dev", "")
        if not detail_path.startswith("/"):
            detail_path = "/" + detail_path
        proxy_url = f"https://byrutgame.org{detail_path}"
    
    try:
        # ä½¿ç”¨ http_client è·å–å†…å®¹ï¼Œè‡ªåŠ¨å¤„ç†é‡è¯•å’Œ User-Agent è½®æ¢
        # ä¼ é€’ verify_ssl=False ä»¥é¿å… SSL é”™è¯¯
        html = await http_client.get_text(proxy_url, verify_ssl=False)
        
        if not html:
            _apply_backup_solution(item, "æ— æ³•è·å–é¡µé¢å†…å®¹")
            return

    except Exception as e:
        logging.error(f"[Byrut] è¯¦æƒ…é¡µè¯·æ±‚å¼‚å¸¸: {e}")
        _apply_backup_solution(item, f"è¯·æ±‚å¼‚å¸¸: {e}")
        return

    soup = BeautifulSoup(html, "html.parser")
    update_node = soup.select_one("div.tupd")
    update_text = update_node.get_text(strip=True) if update_node else ""
    m = re.search(r"(\d{1,2}\s+[Ğ°-ÑĞ-Ğ¯]+\s+\d{4},\s*\d{1,2}:\d{2})", update_text)
    
    if m:
        russian_date = m.group(1)
        # ä¿„æ–‡æœˆä»½æ˜ å°„
        month_map = {
            'ÑĞ½Ğ²Ğ°Ñ€Ñ': '1', 'Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ': '2', 'Ğ¼Ğ°Ñ€Ñ‚Ğ°': '3', 'Ğ°Ğ¿Ñ€ĞµĞ»Ñ': '4',
            'Ğ¼Ğ°Ñ': '5', 'Ğ¸ÑĞ½Ñ': '6', 'Ğ¸ÑĞ»Ñ': '7', 'Ğ°Ğ²Ğ³ÑƒÑÑ‚Ğ°': '8',
            'ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ': '9', 'Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ': '10', 'Ğ½Ğ¾ÑĞ±Ñ€Ñ': '11', 'Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ': '12'
        }
        
        # è§£æä¿„æ–‡æ—¥æœŸ
        parts = russian_date.split()
        if len(parts) >= 3:
            day = parts[0]
            month_ru = parts[1].lower()
            year = parts[2].replace(',', '')
            
            # è½¬æ¢ä¸ºä¸­æ–‡æ ¼å¼
            if month_ru in month_map:
                month = month_map[month_ru]
                # æå–æ—¶é—´éƒ¨åˆ†
                time_match = re.search(r'(\d{1,2}:\d{2})', russian_date)
                time_str = time_match.group(1) if time_match else ""
                
                # æ ¼å¼åŒ–ä¸ºä¸­æ–‡æ—¥æœŸæ ¼å¼
                update_time = f"{year}-{month}-{day} {time_str}".strip()
            else:
                update_time = russian_date  # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·
        else:
            update_time = russian_date
    else:
        update_time = "æœªçŸ¥"

    tor_tag = soup.select_one("a.itemtop_games") or soup.select_one("a:-soup-contains('Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ñ€Ñ€ĞµĞ½Ñ‚')")
    torrent_url = tor_tag["href"] if tor_tag else None
    if torrent_url and torrent_url.startswith("/"):
        torrent_url = f"https://byrutgame.org{torrent_url}"

    item.update({"update_time": update_time, "torrent_url": torrent_url})


async def send_final_forward(group_id, èµåŠ©å†…å®¹: list[str], å•æœº_lines: list[str], è”æœº_lines: list[str], user_id: str = "0", user_nickname: str = "æ¸¸æˆåŠ©æ‰‹"):
    """ä¸€æ¬¡æ€§æ„é€ ï¼šèµåŠ© + å•æœºç‰ˆ + è”æœºç‰ˆï¼ˆèŠ‚ç‚¹å†…ä¸å†å†™æ¸¸æˆåï¼‰"""
    nodes = []

    # 1. èµåŠ©èŠ‚ç‚¹
    # ä½¿ç”¨ base64 ç¼–ç çš„å›¾ç‰‡
    base_dir = "/home/hjh/BOT/NCBOT"
    abs_qq_img_path = QQ_IMG
    qq_img_base64 = image_to_base64(abs_qq_img_path)
    
    sponsor_content = [{"type": "text", "data": {"text": èµåŠ©å†…å®¹[0]}}]
    if qq_img_base64:
        sponsor_content.append({"type": "image", "data": {"file": qq_img_base64}})
    
    # ä»æ¶ˆæ¯ä¸­æå–æ¸¸æˆåç§°ï¼Œç”¨äºæ ‡é¢˜å’Œæ‘˜è¦
    game_title = ""
    for line in å•æœº_lines:
        if "æ¸¸æˆåå­—ï¼š" in line:
            parts = line.split("æ¸¸æˆåå­—ï¼š")
            if len(parts) > 1:
                game_title = parts[1].strip()
                break
    if not game_title:
        for line in è”æœº_lines:
            if "æ¸¸æˆåå­—ï¼š" in line:
                parts = line.split("æ¸¸æˆåå­—ï¼š")
                if len(parts) > 1:
                    game_title = parts[1].strip()
                    break
    if not game_title:
        game_title = "æ¸¸æˆèµ„æº"

    # 1. èµåŠ©èŠ‚ç‚¹
    nodes.append({
        "type": "node",
        "data": {
            "uin": user_id,
            "nickname": user_nickname,
            "content": sponsor_content
        }
    })

    # 2. å•æœºç‰ˆèŠ‚ç‚¹ï¼ˆå»æ‰æ ‡é¢˜è¡Œï¼Œåªå†™ç½‘ç›˜ä¿¡æ¯ï¼‰
    å•æœº_nodes = [{"type": "text", "data": {"text": line}} for line in å•æœº_lines]
    nodes.append({
        "type": "node",
        "data": {
            "uin": user_id,
            "nickname": user_nickname,
            "content": å•æœº_nodes
        }
    })

    # 3. è”æœºç‰ˆèŠ‚ç‚¹ï¼ˆç›´æ¥ä½¿ç”¨å¤„ç†å¥½çš„å†…å®¹ï¼Œä¸å†é‡å¤æ·»åŠ æ ‡é¢˜ï¼‰
    è”æœº_nodes = []
    # ç›´æ¥è¿½åŠ å¤„ç†å¥½çš„å†…å®¹
    if è”æœº_lines:
        è”æœº_nodes.extend([{"type": "text", "data": {"text": line}} for line in è”æœº_lines])
        
        # â‘¢ æ£€æŸ¥æ˜¯å¦æœ‰å¤‡ç”¨å›¾ç‰‡éœ€è¦æ·»åŠ 
        for line in è”æœº_lines:
            if "å¤‡ç”¨å›¾ç‰‡" in line and line.split("å¤‡ç”¨å›¾ç‰‡ï¼š")[1].strip():
                image_path = line.split("å¤‡ç”¨å›¾ç‰‡ï¼š")[1].strip()
                if os.path.exists(image_path):
                    # ä½¿ç”¨ base64 ç¼–ç çš„å›¾ç‰‡
                    if not os.path.isabs(image_path):
                        base_dir = "/home/hjh/BOT/NCBOT"
                        abs_image_path = os.path.join(base_dir, "tool", os.path.basename(image_path))
                    else:
                        abs_image_path = image_path
                    
                    # è½¬æ¢ä¸º base64
                    backup_img_base64 = image_to_base64(abs_image_path)
                    if backup_img_base64:
                        è”æœº_nodes.append({"type": "image", "data": {"file": backup_img_base64}})
                    break
    nodes.append({
        "type": "node",
        "data": {
            "uin": user_id,
            "nickname": user_nickname,
            "content": è”æœº_nodes
        }
    })

    # 4. ä¸€æ¬¡æ€§å‘å‡º
    # è®¡ç®—èµ„æºæ•°é‡
    single_count = len([line for line in å•æœº_lines if "é“¾æ¥" in line])
    multi_count = len([line for line in è”æœº_lines if "ç§å­é“¾æ¥" in line])
    total_count = single_count + multi_count
    
    summary = f"å…±æ‰¾åˆ° {total_count} ä¸ªèµ„æºé“¾æ¥"
    if single_count > 0:
        summary += f" (å•æœº: {single_count} ä¸ª)"
    if multi_count > 0:
        summary += f" (è”æœº: {multi_count} ä¸ª)"
    
    # 5. ä½¿ç”¨å…¨å±€ NapCat æœåŠ¡å‘é€
    return await napcat_service.send_group_forward_msg(
        group_id=group_id,
        nodes=nodes,
        source=game_title,
        summary=summary,
        prompt=f"[{game_title[:30]}]",
        news=[{"text": "ç‚¹å‡»æŸ¥çœ‹æ¸¸æˆèµ„æºè¯¦æƒ…"}]
    )


class SearchSession:
    def __init__(self, user_id, games, task=None):
        self.user_id = user_id
        self.games = games
        self.task = task
        self.processing = False

# -------------------- æ’ä»¶ä¸»ç±» --------------------
class Xydj(BasePlugin):
    name = "xydj"
    version = "1.0"

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.sessions = {}  # group_id -> SearchSession

    async def countdown(self, msg, group_id):
        await asyncio.sleep(40)
        session = self.sessions.get(group_id)
        if session and not session.processing:
            self._cleanup(group_id)
            await self.api.post_group_msg(
                group_id=group_id,
                rtf=MessageChain([Reply(msg.message_id), Text("ç­‰å¾…è¶…æ—¶ï¼Œæ“ä½œå·²å–æ¶ˆã€‚è¯·é‡æ–°æœç´¢")])
            )

    def _cleanup(self, group_id):
        if group_id in self.sessions:
            session = self.sessions[group_id]
            if session.task:
                session.task.cancel()
            del self.sessions[group_id]

    async def process_game_resource(self, game, msg):
        """ç»Ÿä¸€å¤„ç†æ¸¸æˆèµ„æºè·å–å’Œå‘é€çš„å‡½æ•°ï¼ˆå¹¶è¡Œå¤„ç†å•æœºç‰ˆå’Œè”æœºç‰ˆèµ„æºï¼‰"""
        try:
            # è·å–å¤„ç†åçš„åå­—å’Œä¸­æ–‡å±•ç¤ºå
            english_keyword, chinese_display = extract_english_name(game['title'])
            # æ‰“å°æœç´¢ç”¨çš„è‹±æ–‡ååˆ°æ§åˆ¶å°
            print(f"[æœç´¢å…³é”®è¯] ä¸­æ–‡å: {chinese_display}, è‹±æ–‡å: {english_keyword}")

            # å¹¶è¡Œå¤„ç†å•æœºç‰ˆå’Œè”æœºç‰ˆèµ„æº
            async def process_single_player():
                """å¤„ç†å•æœºç‰ˆèµ„æº"""
                å•æœºå†…å®¹ = []
                å•æœº_lines = await extract_download_info(game['url'])
                if å•æœº_lines:
                    å•æœºå†…å®¹.append("ğŸ® ã€å•æœºç‰ˆã€‘\n")
                    å•æœºå†…å®¹.append(f"ğŸ“Œ æ¸¸æˆåå­—ï¼š{chinese_display}\n")   # â† ä¸­æ–‡å±•ç¤ºå
                    # é€è¡ŒåŠ  \n ä¿è¯å¯†ç /é“¾æ¥åéƒ½æ¢è¡Œ
                    for line in å•æœº_lines:
                        if "è§£å‹å¯†ç " in line:
                            å•æœºå†…å®¹.append(f"ğŸ”‘ {line}\n")
                        elif "ç™¾åº¦ç½‘ç›˜" in line:
                            å•æœºå†…å®¹.append(f"ğŸ’¾ {line}\n")
                        elif "é“¾æ¥" in line:
                            å•æœºå†…å®¹.append(f"ğŸŒ {line}\n")
                        else:
                            å•æœºå†…å®¹.append(f"ğŸ“‹ {line}\n")
                else:
                    å•æœºå†…å®¹.append("ğŸ® ã€å•æœºç‰ˆã€‘\n")
                    å•æœºå†…å®¹.append("âŒ æœªæ‰¾åˆ°ç›¸å…³èµ„æº\n")
                return å•æœºå†…å®¹

            async def process_multi_player():
                """å¤„ç†è”æœºç‰ˆèµ„æº"""
                # Byrut è”æœºç‰ˆï¼ˆç”¨è‹±æ–‡å…³é”®è¯æœï¼Œå±•ç¤ºç”¨å®Œæ•´æ ‡é¢˜ï¼‰
                byrut_results = await search_byrut(english_keyword)   # æœç´¢ä»èµ°è‹±æ–‡
                # æ‰“å°æœç´¢åˆ°çš„hrefåˆ°æ§åˆ¶å°
                for item in byrut_results:
                    print(f"[Byrut] æ‰¾åˆ°è”æœºèµ„æº: {item['href']}")
                    await fetch_byrut_detail(item)
                
                # è”æœºç‰ˆå†…å®¹ï¼ˆè‹±æ–‡å±•ç¤ºå + æ›´æ–°æ—¶é—´ + ç§å­ï¼‰
                è”æœºå†…å®¹ = []
                if byrut_results:
                    è”æœºå†…å®¹.append("ğŸ® ã€è”æœºç‰ˆã€‘\n")
                    è”æœºå†…å®¹.append(f"ğŸ“Œ æ¸¸æˆåå­—ï¼š{english_keyword}\n")   # â† è‹±æ–‡å±•ç¤ºå
                    
                    for idx, item in enumerate(byrut_results, 1):
                        if len(byrut_results) > 1:
                            è”æœºå†…å®¹.append(f"\n{idx}. èµ„æº {idx}\n")
                        
                        è”æœºå†…å®¹.append(f"ğŸ”‘ è§£å‹å¯†ç ï¼šã€online-fix.meã€‘\n")
                        è”æœºå†…å®¹.append(f"â° æ›´æ–°æ—¶é—´ï¼š{item['update_time']}\n")
                        
                        if item.get('torrent_url'):
                            è”æœºå†…å®¹.append(f"ğŸŒ ç§å­é“¾æ¥ï¼š{item['torrent_url']}\n")
                        else:
                            è”æœºå†…å®¹.append(f"âŒ ç§å­é“¾æ¥ï¼šæš‚æ— \n")
                        
                        # å¦‚æœæœ‰å¤‡ç”¨å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡æ ‡è®°
                        if item.get('backup_image'):
                            è”æœºå†…å®¹.append(f"ğŸ–¼ï¸ å¤‡ç”¨å›¾ç‰‡ï¼š{item['backup_image']}\n")
                    
                    è”æœºå†…å®¹.append("ğŸ’¡ ä½¿ç”¨æç¤ºï¼šä¸‹è½½ç§å­åä½¿ç”¨BTå®¢æˆ·ç«¯æ‰“å¼€å³å¯\n")
                else:
                    è”æœºå†…å®¹.append("ğŸ® ã€è”æœºç‰ˆã€‘\n")
                    è”æœºå†…å®¹.append("âŒ æœªæ‰¾åˆ°ç›¸å…³èµ„æº\n")
                    è”æœºå†…å®¹.append("ğŸ”‘ é€šç”¨è§£å‹å¯†ç ï¼šã€online-fix.meã€‘\n")
                    è”æœºå†…å®¹.append("ğŸ“š æŸ¥çœ‹æ•™ç¨‹ï¼šã€Šæœç´¢å’Œä½¿ç”¨è”æœºæ¸¸æˆã€‹\n")
                    è”æœºå†…å®¹.append("ğŸŒ https://www.yuque.com/lanmeng-ijygo/ey7ah4/fe9hfep86cw7coku?singleDoc#\n")
                return è”æœºå†…å®¹

            # å¹¶è¡Œæ‰§è¡Œå•æœºç‰ˆå’Œè”æœºç‰ˆèµ„æºè·å–
            å•æœºå†…å®¹, è”æœºå†…å®¹ = await asyncio.gather(
                process_single_player(),
                process_multi_player(),
                return_exceptions=True  # æ•è·å¼‚å¸¸ï¼Œç¡®ä¿ä¸€ä¸ªä»»åŠ¡å¤±è´¥ä¸ä¼šå½±å“å¦ä¸€ä¸ª
            )
            
            # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
            if isinstance(å•æœºå†…å®¹, Exception):
                print(f"å•æœºç‰ˆèµ„æºè·å–å¤±è´¥: {å•æœºå†…å®¹}")
                å•æœºå†…å®¹ = ["ã€å•æœºç‰ˆã€‘è·å–èµ„æºæ—¶å‡ºé”™\n"]
            
            if isinstance(è”æœºå†…å®¹, Exception):
                print(f"è”æœºç‰ˆèµ„æºè·å–å¤±è´¥: {è”æœºå†…å®¹}")
                è”æœºå†…å®¹ = ["ã€è”æœºç‰ˆã€‘è·å–èµ„æºæ—¶å‡ºé”™"]
            
            # 4. ä¸€æ¬¡æ€§è½¬å‘
            èµåŠ©å†…å®¹ = ["æ­£è§„æµé‡å¡ä¸æ˜¯ç‰©è”å¡ï¼Œå®˜æ–¹å®¢æœå¯æŸ¥å¥—é¤ï¼Œå®˜æ–¹APPå¯è‡ªå·±æŸ¥ä½™é¢\næœ‰é—®é¢˜è¯·æ‰£ä¸»äºº~~ï¼š\nhttps://ym.ksjhaoka.com/?s=q9thdGIs326398"]
            
            # å¦‚æœä¸¤æ¡éƒ½ç©ºï¼Œå†æç¤ºã€Œéƒ¨åˆ†æœªæ‰¾åˆ°ã€
            if not å•æœºå†…å®¹ and not è”æœºå†…å®¹:
                await self.api.post_group_msg(
                    group_id=msg.group_id,
                    rtf=MessageChain([Reply(msg.message_id), Text("ã€è”æœºç‰ˆã€‘æœªæ‰¾åˆ°ä»»ä½•èµ„æºï¼Œå¯èƒ½å…³é”®è¯ä¸åŒ¹é…æˆ–æœåŠ¡å™¨å¼‚å¸¸")])
                )
                return
            
            # å¦åˆ™ã€Œæœ‰å¤šå°‘å‘å¤šå°‘ã€
            await send_final_forward(msg.group_id, èµåŠ©å†…å®¹, å•æœºå†…å®¹, è”æœºå†…å®¹, str(msg.user_id), msg.sender.nickname)
        except Exception as e:
            await self.api.post_group_msg(
                group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text(f"å¤„ç†å¤±è´¥: {str(e)}")])
            )

    async def process_single_game(self, game, msg):
        """å¤„ç†å•ä¸ªæ¸¸æˆçš„è‡ªåŠ¨è½¬å‘"""
        await self.process_game_resource(game, msg)

    @bot.group_event
    async def on_group_message(self, msg: GroupMessage):
        # è·å–å½“å‰ç¾¤ç»„çš„ä¼šè¯
        session = self.sessions.get(msg.group_id)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç­‰å¾…å›å¤çš„çŠ¶æ€ï¼Œå¹¶ä¸”å‘é€è€…æ˜¯å‘½ä»¤å‘èµ·äºº
        if session and msg.user_id == session.user_id:
            if session.processing:
                return
            
            choice = re.sub(r'\[CQ:[^\]]+\]', '', msg.raw_message).strip()
            
            # å–æ¶ˆæ“ä½œ
            if choice == "0":
                await self.api.post_group_msg(
                    group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text("æ“ä½œå·²å–æ¶ˆã€‚")])
                )
                self._cleanup(msg.group_id)
                return
            
            # éªŒè¯é€‰æ‹©
            if not choice.isdigit() or not 1 <= int(choice) <= len(session.games):
                await self.api.post_group_msg(
                    group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text("å›å¤é”™è¯¯ï¼Œæ“ä½œå·²å–æ¶ˆã€‚è¯·é‡æ–°æœç´¢æ¸¸æˆã€‚")])
                )
                self._cleanup(msg.group_id)
                return
            
            choice = int(choice)
            await self.api.post_group_msg(
                group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text(f"å·²é€‰æ‹©ç¬¬ {choice} ä¸ªæ¸¸æˆï¼Œè¯·ç­‰å¾…å¤§æ¦‚1åˆ†é’Ÿï¼ï¼ï¼")])
            )
            
            session.processing = True
            # å–æ¶ˆè¶…æ—¶è®¡æ—¶å™¨
            if session.task:
                session.task.cancel()
                session.task = None
            
            try:
                game = session.games[choice - 1]
                await self.process_game_resource(game, msg)
            except Exception as e:
                await self.api.post_group_msg(
                    group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text(f"å¤„ç†å¤±è´¥: {str(e)}")])
                )
            finally:
                self._cleanup(msg.group_id)
        
        # å¤„ç†æ–°çš„æœç´¢å‘½ä»¤
        elif msg.raw_message.strip().startswith("æœç´¢"):
            game_name = msg.raw_message.strip()[2:].strip()
            if not game_name:
                await self.api.post_group_msg(
                    group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text("ä½¿ç”¨æ–¹æ³•ï¼šæœç´¢+æ¸¸æˆåç§°ï¼Œä¾‹å¦‚ï¼šæœç´¢ æ–‡æ˜6")])
                )
                return
            
            try:
                text_result, games = await search_game(game_name)
                if not text_result:
                    await self.api.post_group_msg(
                        group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text("æœªæ‰¾åˆ°ï¼Œæ£€æŸ¥æ¸¸æˆåå­—ï¼Œæœç´¢æ¸¸æˆå­—æ•°å°‘ä¸€ç‚¹è¯•è¯•å‘¢")])
                    )
                    return
                
                # å¦‚æœåªæœ‰ä¸€ä¸ªæ¸¸æˆç»“æœï¼Œç›´æ¥è‡ªåŠ¨å¤„ç†
                if len(games) == 1:
                    await self.api.post_group_msg(
                        group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text("æœç´¢åˆ°1ä¸ªæ¸¸æˆï¼Œè‡ªåŠ¨ä¸ºæ‚¨è·å–èµ„æºä¿¡æ¯ï¼Œè¯·ç­‰å¾…å¤§æ¦‚1åˆ†é’Ÿï¼ï¼ï¼")])
                    )
                    await self.process_single_game(games[0], msg)
                    return
                
                # å¤šä¸ªæ¸¸æˆç»“æœï¼Œåˆ›å»ºæ–°ä¼šè¯
                await self.api.post_group_msg(
                    group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text(f"ğŸ¯ å‘ç° {len(games)} æ¬¾æ¸¸æˆ\n{text_result}\nâ° 30ç§’å†…å›å¤åºå·é€‰æ‹© | å›å¤ 0 å–æ¶ˆæ“ä½œ")])
                )
                
                # åˆ›å»ºä¼šè¯å¹¶ä¿å­˜
                session = SearchSession(msg.user_id, games)
                session.task = asyncio.create_task(self.countdown(msg, msg.group_id))
                self.sessions[msg.group_id] = session
                
            except Exception as e:
                logging.exception(f"æœç´¢å‡ºé”™: {e}")
                await self.api.post_group_msg(
                    group_id=msg.group_id, rtf=MessageChain([Reply(msg.message_id), Text("å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")])
                )

    async def on_load(self):
        print(f"{self.name} æ’ä»¶å·²åŠ è½½ï¼Œç‰ˆæœ¬: {self.version}")
